{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.395695100Z",
     "start_time": "2024-02-01T07:37:27.888988900Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import argparse\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from train.clf_evaluate import evaluate_model\n",
    "from utils.data_loading import ClassificationDatasetJson\n",
    "from utils.utils import EarlyStopping, stratified_split\n",
    "from models.clf.ResNet.resnet import ResNetClassification\n",
    "from models.clf.EfficientNet.model import EfficientNetClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37df1cc15ab397b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.410694900Z",
     "start_time": "2024-02-01T07:37:28.397697100Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'EFFICIENT-NET'\n",
    "num_classes = 2\n",
    "size = (256, 256)\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "amp = True\n",
    "learning_rate = 1e-4\n",
    "val = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a61e6a71700aa61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.429391Z",
     "start_time": "2024-02-01T07:37:28.411700Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "424abe84f9fb28e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.598348800Z",
     "start_time": "2024-02-01T07:37:28.428392100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "MODEL = ['RES-NET', 'EFFICIENT-NET']\n",
    "model = None\n",
    "assert model_name.upper() in MODEL, f'Model optional type are :{MODEL}, please choose available model_name'\n",
    "\n",
    "if model_name.upper() == 'RES-NET':\n",
    "    model = ResNetClassification(num_classes)\n",
    "elif model_name.upper() == 'EFFICIENT-NET':\n",
    "    model = EfficientNetClassification(in_channels=3, num_classes=num_classes)\n",
    "model = model.to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da385a08784d42b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.642037800Z",
     "start_time": "2024-02-01T07:37:28.602349400Z"
    }
   },
   "outputs": [],
   "source": [
    "# set save directory\n",
    "now_time = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "now_h = datetime.now().strftime(\"%H\")\n",
    "\n",
    "dir_checkpoint = Path(f'./MelNv/checkpoints/{model_name}')\n",
    "dir_indicators = Path(f'./MelNv/indicators/{model_name}')\n",
    "Path(f'{dir_checkpoint}/{now_time}/{now_h}').mkdir(parents=True, exist_ok=True)\n",
    "Path(f'{dir_indicators}/{now_time}/{now_h}').mkdir(parents=True, exist_ok=True)\n",
    "dir_checkpoint_save = Path(f'{dir_checkpoint}/{now_time}/{now_h}')\n",
    "dir_indicators_save = Path(f'{dir_indicators}/{now_time}/{now_h}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cba8630fdef6a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.644043200Z",
     "start_time": "2024-02-01T07:37:28.614351800Z"
    }
   },
   "outputs": [],
   "source": [
    "# set and save header indicators in csv\n",
    "indicators_header = ['epoch', 'train_loss', 'learning_rate','train_acc', 'train_precision', 'train_recall', 'train_f1', 'train_mAP','val_acc', 'val_precision', 'val_recall', 'val_f1', 'val_mAP']\n",
    "epoch_csv_path = f'{dir_indicators_save}/train_indicators.csv'\n",
    "with open(epoch_csv_path, 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(indicators_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3d7279d309cc28d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.704347200Z",
     "start_time": "2024-02-01T07:37:28.631866100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading json file successfully!\n",
      "INFO:root:Start training:\n",
      "Epochs:             100\n",
      "Batch size:         8\n",
      "Learning rate:      0.0001\n",
      "Training size:      8478\n",
      "Validation size:    2119\n",
      "Checkpoints:        True\n",
      "Device:             cuda\n",
      "Images size:        (256, 256)\n",
      "Mixed Precision:    True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create dataset \n",
    "json_data_path = 'E:/Code/Git/All_Model/datasets/json/MelNvTrain_dataset.json'\n",
    "dataset = ClassificationDatasetJson(json_dir=json_data_path, size=size)\n",
    "n_val = int(len(dataset) * val)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
    "\n",
    "# create data loaders\n",
    "loader_args = dict(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True)\n",
    "train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
    "val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "# logging\n",
    "logging.info(f'''Start training:\n",
    "Epochs:             {epochs}\n",
    "Batch size:         {batch_size}\n",
    "Learning rate:      {learning_rate}\n",
    "Training size:      {n_train}\n",
    "Validation size:    {n_val}\n",
    "Checkpoints:        {True}\n",
    "Device:             {device.type}\n",
    "Images size:        {size}\n",
    "Mixed Precision:    {amp}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65fe28551eba951e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:37:28.708347500Z",
     "start_time": "2024-02-01T07:37:28.678043300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=10)\n",
    "grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "best_acc = 0.0\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d52ec468487ccabd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:43:41.135903700Z",
     "start_time": "2024-02-01T07:43:09.049659700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 16/8478 [00:43<6:20:00,  2.69s/image, loss (batch)=0.679]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(proba_labels, true_labels)\n\u001b[0;32m     33\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 34\u001b[0m \u001b[43mgrad_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     36\u001b[0m grad_scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n",
      "File \u001b[1;32mE:\\CondaEvens\\PyTorch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\CondaEvens\\PyTorch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(1, epochs + 1):\n",
    "    model.train()\n",
    "    \n",
    "    val_times_every_epoch = 0 \n",
    "    \n",
    "    # save epoch indicators\n",
    "    epoch_train_loss = 0\n",
    "    epoch_train_acc = 0\n",
    "    epoch_train_precision = 0\n",
    "    epoch_train_recall = 0\n",
    "    epoch_train_f1 = 0\n",
    "    epoch_train_ap = 0\n",
    "\n",
    "    epoch_val_acc = 0\n",
    "    epoch_val_precision = 0\n",
    "    epoch_val_recall = 0\n",
    "    epoch_val_f1 = 0\n",
    "    epoch_val_ap = 0\n",
    "    \n",
    "    with (tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='image') as pbar):\n",
    "        for batch in train_loader:\n",
    "            images, true_labels = batch['images'], batch['labels']\n",
    "            images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "            true_labels = true_labels.to(device=device, dtype=torch.long)\n",
    "            \n",
    "            with torch.autocast(device.type if device.type != 'mps' else ' cpu', enabled=amp):\n",
    "                proba_labels = model(images)\n",
    "                pred_labels = torch.argmax(F.softmax(proba_labels, dim=1), dim=1)\n",
    "        \n",
    "                loss = criterion(proba_labels, true_labels)\n",
    "                \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            grad_scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "            pbar.update(images.shape[0])\n",
    "            \n",
    "            # calculate indicators\n",
    "            true_labels_cpu = true_labels.cpu().numpy()\n",
    "            proba_labels_cpu = proba_labels.detach().cpu().numpy()\n",
    "            pred_labels_cpu = pred_labels.detach().cpu().numpy()\n",
    "            \n",
    "            train_acc = accuracy_score(true_labels_cpu, pred_labels_cpu, normalize=True)\n",
    "            train_precision = precision_score(true_labels_cpu, pred_labels_cpu, average='binary', zero_division=0)\n",
    "            train_recall = recall_score(true_labels_cpu, pred_labels_cpu, zero_division=0)\n",
    "            train_f1 = f1_score(true_labels_cpu, pred_labels_cpu, zero_division=0)\n",
    "            train_ap = average_precision_score(true_labels_cpu, proba_labels_cpu[:, 1])\n",
    "            \n",
    "            # update epoch information\n",
    "            global_step += 1\n",
    "            epoch_train_loss += loss.cpu().detach().numpy()\n",
    "            epoch_train_acc += train_acc\n",
    "            epoch_train_precision += train_precision\n",
    "            epoch_train_recall += train_recall\n",
    "            epoch_train_f1 += train_f1\n",
    "            epoch_train_ap += train_ap\n",
    "            pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "            \n",
    "             # Start validation evaluate\n",
    "            division_step = (n_train // (5 * batch_size))  # Evaluation round every 5 batch size do a evaluation\n",
    "            if (global_step % division_step == 0) & (division_step > 0):\n",
    "                val_times_every_epoch += 1\n",
    "                \n",
    "                # indicators in every evaluate\n",
    "                val_acc, val_precision, val_recall, val_f1, val_ap = evaluate_model(model, val_loader, device, amp, num_classes)\n",
    "\n",
    "                # average score for every evaluate\n",
    "                val_acc_avg = sum(val_acc) / max(len(val_loader), 1)\n",
    "                val_precision_avg = sum(val_precision) / max(len(val_loader), 1)\n",
    "                val_recall_avg = sum(val_recall) / max(len(val_loader), 1)\n",
    "                val_f1_avg = sum(val_f1) / max(len(val_loader), 1)\n",
    "                val_ap_avg = sum(val_ap) / max(len(val_loader), 1)\n",
    "\n",
    "                logging.info('Validation ACC score: {}'.format(np.round(val_acc_avg, 3)))\n",
    "                logging.info('Validation Precision score: {}'.format(np.round(val_precision_avg, 3)))\n",
    "                logging.info('Validation Recall score: {}'.format(np.round(val_recall_avg, 3)))\n",
    "                logging.info('Validation F1 score: {}'.format(np.round(val_f1_avg, 3)))\n",
    "                logging.info('Validation AP score: {}'.format(np.round(val_ap_avg, 3)))\n",
    "\n",
    "                # score add in epoch indicators\n",
    "                epoch_val_acc += val_acc_avg\n",
    "                epoch_val_precision += val_precision_avg\n",
    "                epoch_val_recall += val_recall_avg\n",
    "                epoch_val_f1 += val_f1_avg\n",
    "                epoch_val_ap += val_ap_avg\n",
    "\n",
    "                # update scheduler\n",
    "                scheduler.step(val_recall_avg)\n",
    "    \n",
    "    epoch_val_acc_avg = np.round((epoch_val_acc / val_times_every_epoch), 3)\n",
    "    \n",
    "    # set early stop\n",
    "    stop = early_stopping(epoch_val_acc_avg)\n",
    "    if stop:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84334ffc68507148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T07:38:06.906170300Z",
     "start_time": "2024-02-01T07:38:06.905170600Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d8362da63e37e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-02-01T07:38:06.906170300Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
